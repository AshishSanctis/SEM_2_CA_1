{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b91f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, explode\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.types import DoubleType, ArrayType, StringType\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import col, udf\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.types import DoubleType, ArrayType, StringType\n",
    "from pyspark.sql.types import DoubleType\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql.functions import explode\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30695fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/02 23:30:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Importing PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read CSV\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e130da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ubuntu-22.04-arm64.shared:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425efe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "data_df = spark.read.load(\"hdfs://localhost:9000/user1/train.csv\", format=\"csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4bc5638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          3|  more like funchuck|\"Gave this to my ...|\n",
      "|          5|           Inspiring|I hope a lot of p...|\n",
      "|          5|The best soundtra...|I'm reading a lot...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379101b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3000000\n",
      "Column names: ['class_index', 'review_title', 'review_text']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check the number of rows\n",
    "num_rows = data_df.count()\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "# Check the list of column names\n",
    "column_names = data_df.columns\n",
    "print(\"Column names:\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ec3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- class_index: string (nullable = true)\n",
      " |-- review_title: string (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing Schema\n",
    "print(\"Schema:\")\n",
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f45ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          3|  more like funchuck|\"Gave this to my ...|\n",
      "|          5|           Inspiring|I hope a lot of p...|\n",
      "|          5|The best soundtra...|I'm reading a lot...|\n",
      "|          4|    Chrono Cross OST|\"The music of Yas...|\n",
      "|          5| Too good to be true|Probably the grea...|\n",
      "|          5|There's a reason ...|There's a reason ...|\n",
      "|          1|        Buyer beware|\"This is a self-p...|\n",
      "|          4|Errors, but great...|I was a dissapoin...|\n",
      "|          1|          The Worst!|A complete waste ...|\n",
      "|          1|           Oh please|I guess you have ...|\n",
      "|          1|Awful beyond belief!|\"I feel I have to...|\n",
      "|          4|A romantic zen ba...|\"When you hear fo...|\n",
      "|          5|Lower leg comfort...|Excellent stockin...|\n",
      "|          3|Delivery was very...|It took almost 3 ...|\n",
      "|          2|sizes recomended ...|sizes are much sm...|\n",
      "|          3|            Overbury|Full of intrigue ...|\n",
      "|          1|Another Abysmal D...|\"Rather than scra...|\n",
      "|          4|Wardell's book is...|\"Steven Wardell's...|\n",
      "|          4|i liked this albu...|\"I heard a song o...|\n",
      "|          3|Better than I tho...|I wrote a harsh r...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show sample rows after removing null values\n",
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54a2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'class_index' column and perform aggregation\n",
    "aggregated_df = data_df.groupBy(\"class_index\").agg(\n",
    "    F.count(\"*\").alias(\"count_reviews\"),\n",
    "    F.avg(\"class_index\").alias(\"avg_class_index\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3538bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------+\n",
      "|class_index|count_reviews|avg_class_index|\n",
      "+-----------+-------------+---------------+\n",
      "|          3|       600000|            3.0|\n",
      "|          5|       600000|            5.0|\n",
      "|          1|       600000|            1.0|\n",
      "|          4|       600000|            4.0|\n",
      "|          2|       600000|            2.0|\n",
      "+-----------+-------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show the aggregated DataFrame\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac64acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by a single column\n",
    "sorted_df = data_df.orderBy(\"class_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b335531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:==============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          1|  Read Dante Instead|Reading this book...|\n",
      "|          1|         Didn't work|This tape was imm...|\n",
      "|          1|        unhappy feet|A disappointment ...|\n",
      "|          1|                Poor|\"This is actually...|\n",
      "|          1|Really? Magic gecko?|Right about the t...|\n",
      "|          1|             Useless|I don't think it ...|\n",
      "|          1|             Bad Buy|I bought this rin...|\n",
      "|          1|  Poor Sound Quality|The sound quality...|\n",
      "|          1|Shouldn't be adve...|I gave this toy t...|\n",
      "|          1|     Waste of money.|This thing is a p...|\n",
      "|          1|     A Steaming Pile|\"This album is ho...|\n",
      "|          1|          Wrong item|Ordered the Belki...|\n",
      "|          1|     TOTALLY USELESS|\"Not only is the ...|\n",
      "|          1|Product did not work|This didn't work ...|\n",
      "|          1|Statistics for st...|This book will pr...|\n",
      "|          1|Auto reverses and...|The sound quality...|\n",
      "|          1|    Frustrating game|The good news is ...|\n",
      "|          1|Has a loud clicki...|Makes a gear grid...|\n",
      "|          1|    Absolutely Awful|This product does...|\n",
      "|          1|           Defective|I purchased this ...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Showing the sorted DataFrame\n",
    "sorted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deede37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          5|For those of us w...|\"Louis adventures...|\n",
      "|          5|   Coolest game eva!|I love the nancy ...|\n",
      "|          5|    Soft and Cuddly!|My son loves his ...|\n",
      "|          5|      Kitchen Review|My husband and I ...|\n",
      "|          5|           excellent|Exactly what I no...|\n",
      "|          5|Kind of creepy bu...|\"In the begining ...|\n",
      "|          5|A Reference Recor...|In the mid '70s, ...|\n",
      "|          5|great product at ...|I have purchased ...|\n",
      "|          5|      The New Empire|From the other st...|\n",
      "|          5|          Great pan!|This is a great q...|\n",
      "|          5|Everything a roma...|Just finished thi...|\n",
      "|          5|this is the one y...|best value in a t...|\n",
      "|          5|               KPT 5|I have KPT 3,5,6 ...|\n",
      "|          5|  Norpro popover pan|We had popovers b...|\n",
      "|          5|       giving it all|Real life lyrics ...|\n",
      "|          5|works perfect in ...|bought this and w...|\n",
      "|          5|On time and what ...|See above. I am w...|\n",
      "|          5|             Punchy!|Can't believe I h...|\n",
      "|          5|    Wow! Hot hot hot|Jessie is a stron...|\n",
      "|          5|Great gear, impre...|As good as a Colu...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sort in descending order, using desc() function\n",
    "sorted_desc_df = data_df.orderBy(data_df[\"class_index\"].desc())\n",
    "sorted_desc_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8890a6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          1|                null|\"I remember order...|\n",
      "|          1|                null|\"I was extremely ...|\n",
      "|          1|                null|Just wanted to vo...|\n",
      "|          1|                null|Can't write a rev...|\n",
      "|          1|                null|\"Some good rockin...|\n",
      "|          1|                null|I didn't really c...|\n",
      "|          1|                null|These guys sure h...|\n",
      "|          1|                null|I ordered a 12 fo...|\n",
      "|          1|                null|\"Unless you're a ...|\n",
      "|          1|                null|This is lightweig...|\n",
      "|          1|                null|And here we have ...|\n",
      "|          1|                null|The battery was p...|\n",
      "|          1|                   !|\"This book is com...|\n",
      "|          1|! - STAY AWAY! WO...|Please for the lo...|\n",
      "|          1|! CAUTION - NOT T...|!! CAUTION!!Re-re...|\n",
      "|          1|! DANGER! This fi...|This is an excell...|\n",
      "|          1|! LONG LIVE THE F...|\"Uau, what a bad ...|\n",
      "|          1|! SOUNDS LIKE HE ...|Busta rhymes is a...|\n",
      "|          1|! WARNING - DO NO...|\"I purchased my D...|\n",
      "|          1|! WARNING ... WAR...|Warning, the game...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sorting by multiple columns\n",
    "multi_sorted_df = data_df.orderBy(\"class_index\", \"review_title\")\n",
    "multi_sorted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c152b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering rows where class_index is equal to 5\n",
    "filtered_df = data_df.filter(data_df[\"class_index\"] == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206b21e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data:\n",
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          5|           Inspiring|I hope a lot of p...|\n",
      "|          5|The best soundtra...|I'm reading a lot...|\n",
      "|          5| Too good to be true|Probably the grea...|\n",
      "|          5|There's a reason ...|There's a reason ...|\n",
      "|          5|Lower leg comfort...|Excellent stockin...|\n",
      "|          5|CHECK OUT THE K60...|Greetings. Kodak ...|\n",
      "|          5|                ahhh|These will more t...|\n",
      "|          5|   Excellent Product|This is an excell...|\n",
      "|          5|\"To \"\"Disappointe...|\"You said \"\"...bu...|\n",
      "|          5|Awesome - wanna u...|It's just awesome...|\n",
      "|          5|\"Very Happy - Has...|\"I got this machi...|\n",
      "|          5|This is a very go...|Many useful conce...|\n",
      "|          5|Great reference b...|It seems somebody...|\n",
      "|          5|Here is a little ...|After you watch a...|\n",
      "|          5|Rochelle explains...|Wondering what th...|\n",
      "|          5|Spreading a Passi...|\"Piper has a pass...|\n",
      "|          5|supermarionation ...|if you love thund...|\n",
      "|          5|   Excellent Service|Recieved this ite...|\n",
      "|          5|    Dk Travel guides|The Dk Travel gui...|\n",
      "|          5|creativity for ev...|did you know this...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print filtered data\n",
    "print(\"Filtered Data:\")\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4ed398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          3|  more like funchuck|\"Gave this to my ...|\n",
      "|          5|           Inspiring|I hope a lot of p...|\n",
      "|          5|The best soundtra...|I'm reading a lot...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b429827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------+\n",
      "|class_index|review_title|review_text|\n",
      "+-----------+------------+-----------+\n",
      "|    3000000|     3000000|    3000000|\n",
      "+-----------+------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Count null values in each column\n",
    "null_counts = data_df.agg(*[count(col(c).isNull().cast(\"int\")).alias(c) for c in data_df.columns])\n",
    "\n",
    "# Show the null counts\n",
    "null_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d1d8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|\n",
      "+-----------+--------------------+--------------------+\n",
      "|          3|  more like funchuck|\"Gave this to my ...|\n",
      "|          5|           Inspiring|I hope a lot of p...|\n",
      "|          5|The best soundtra...|I'm reading a lot...|\n",
      "|          4|    Chrono Cross OST|\"The music of Yas...|\n",
      "|          5| Too good to be true|Probably the grea...|\n",
      "+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show a sample of the DataFrame\n",
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2515f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty review_title: 0\n",
      "Number of rows with empty review_text: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter for rows where review_title or review_text is empty\n",
    "empty_title_df = data_df.filter(col(\"review_title\") == \"\")\n",
    "empty_text_df = data_df.filter(col(\"review_text\") == \"\")\n",
    "\n",
    "# Count the number of rows with empty review_title and review_text\n",
    "empty_title_count = empty_title_df.count()\n",
    "empty_text_count = empty_text_df.count()\n",
    "\n",
    "print(\"Number of rows with empty review_title:\", empty_title_count)\n",
    "print(\"Number of rows with empty review_text:\", empty_text_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feb08756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+\n",
      "|class_index|        review_title|         review_text|                text|\n",
      "+-----------+--------------------+--------------------+--------------------+\n",
      "|          3|  more like funchuck|\"Gave this to my ...|more like funchuc...|\n",
      "|          5|           Inspiring|I hope a lot of p...|Inspiring I hope ...|\n",
      "|          5|The best soundtra...|I'm reading a lot...|The best soundtra...|\n",
      "|          4|    Chrono Cross OST|\"The music of Yas...|Chrono Cross OST ...|\n",
      "|          5| Too good to be true|Probably the grea...|Too good to be tr...|\n",
      "|          5|There's a reason ...|There's a reason ...|There's a reason ...|\n",
      "|          1|        Buyer beware|\"This is a self-p...|Buyer beware \"Thi...|\n",
      "|          4|Errors, but great...|I was a dissapoin...|Errors, but great...|\n",
      "|          1|          The Worst!|A complete waste ...|The Worst! A comp...|\n",
      "|          1|           Oh please|I guess you have ...|Oh please I guess...|\n",
      "|          1|Awful beyond belief!|\"I feel I have to...|Awful beyond beli...|\n",
      "|          4|A romantic zen ba...|\"When you hear fo...|A romantic zen ba...|\n",
      "|          5|Lower leg comfort...|Excellent stockin...|Lower leg comfort...|\n",
      "|          3|Delivery was very...|It took almost 3 ...|Delivery was very...|\n",
      "|          2|sizes recomended ...|sizes are much sm...|sizes recomended ...|\n",
      "|          3|            Overbury|Full of intrigue ...|Overbury Full of ...|\n",
      "|          1|Another Abysmal D...|\"Rather than scra...|Another Abysmal D...|\n",
      "|          4|Wardell's book is...|\"Steven Wardell's...|Wardell's book is...|\n",
      "|          4|i liked this albu...|\"I heard a song o...|i liked this albu...|\n",
      "|          3|Better than I tho...|I wrote a harsh r...|Better than I tho...|\n",
      "+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# Concatenate review_title and review_text into a new column named text\n",
    "data_df = data_df.withColumn('text', concat_ws(' ', data_df['review_title'], data_df['review_text']))\n",
    "data_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
